{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d611e4a1-71db-48df-af5f-7af6acef6de5",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee6dc36-62d4-4977-8ef5-8c0826f35eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 11:22:14.860277: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 11:22:14.860462: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import tensorflow\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "'''\n",
    "ERROR : load_model 'str' object has no attribute 'decode'\n",
    "\n",
    "SOLVED:\n",
    "pip uninstall h5py\n",
    "pip install h5py==2.10.0\n",
    "'''\n",
    "\n",
    "model = load_model(\"yoonjungchoi_mnist_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3322a5b-814d-4d79-8add-4ae90015ec28",
   "metadata": {},
   "source": [
    "### Options for webcam or video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130e69b8-072c-4c8e-a873-0f1f85575e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option to support both live webcam [0], saved video file [1]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration sec-  12.566666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "print(\"Option to support both live webcam [0], saved video file [1]\")\n",
    "user_input = int(input())\n",
    "cp = 0\n",
    "out = 0\n",
    "\n",
    "if user_input == 0:\n",
    "    cp = cv2.VideoCapture(0)\n",
    "    w = round(cp.get(cv2.CAP_PROP_FRAME_WIDTH)) #1280\n",
    "    h = round(cp.get(cv2.CAP_PROP_FRAME_HEIGHT)) #720\n",
    "    fps = cp.get(cv2.CAP_PROP_FPS) #29\n",
    "    #fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter('webcam_mnist_output.mp4', fourcc, fps, (w, h))\n",
    "    out_pre = cv2.VideoWriter('webcam_mnist_pre_output.mp4', fourcc, fps, (w, h))\n",
    "\n",
    "elif user_input == 1:\n",
    "    cp = cv2.VideoCapture('SID7062.mp4')\n",
    "    w = round(cp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = round(cp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cp.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cp.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('duration sec- ' ,frame_count/fps)\n",
    "    #fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter('video_mnist_output.mp4', fourcc, fps, (w, h))\n",
    "    out_pre = cv2.VideoWriter('video_mnist_pre_output.mp4', fourcc, fps, (w, h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf48e9a-e9cd-4ddb-a5d8-58fa025c8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# webcam size\n",
    "cp.set(3, 5*128)\n",
    "cp.set(4, 5*128)\n",
    "\n",
    "#input mage size of model\n",
    "SIZE = 28\n",
    "\n",
    "before_cropped_digit=0\n",
    "\n",
    "#cropped images for each digits\n",
    "def extract_digit(frame, rect, pad = 10):\n",
    "    x, y, w, h = rect\n",
    "    \n",
    "    #cropped image with padding\n",
    "    cropped_digit = gray_img[y-pad:y+h+pad, x-pad:x+w+pad]\n",
    "    #normalization\n",
    "    cropped_digit = cropped_digit/255.0\n",
    "    \n",
    "    #crop with squared\n",
    "    max_wh = max(w,h)\n",
    "    w_pad = int((max_wh-w)/2)\n",
    "    h_pad = int((max_wh-h)/2)\n",
    "    cropped_digit_pad = gray_img[y-h_pad:y+h+h_pad, x-w_pad:x+w+w_pad].copy() \n",
    "    cropped_digit_pad = cropped_digit_pad/255.0\n",
    "\n",
    "    #have certain shapes\n",
    "    if cropped_digit_pad.shape[0] >= 32 and cropped_digit_pad.shape[1] >= 32:\n",
    "    #if cropped_digit_pad is not None:\n",
    "        #To train cropped image on model, SIZE should be 28*28\n",
    "        #cropped_digit = cv2.resize(cropped_digit, (SIZE, SIZE))\n",
    "        cropped_digit = cv2.resize(cropped_digit_pad, (SIZE, SIZE))\n",
    "        #cv2.imshow('cropped_digit_pad',cropped_digit)\n",
    "    else:\n",
    "        #too small and return nothing\n",
    "        return\n",
    "    return cropped_digit;\n",
    "\n",
    "def preprocessing(frame, tresh = 90):\n",
    "    \n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    #adaptive here does better with variable lighting:\n",
    "    gray_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY_INV, blockSize = 321, C = 28)\n",
    "    return gray_img\n",
    "\n",
    "    #-------canny is not stable-------#\n",
    "    '''\n",
    "    grayimage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    \n",
    "    cannyimage = cv2.Canny(grayimage, 100, 200)\n",
    "    return cannyimage\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003dd61-c637-40a0-b72b-fc956134bc69",
   "metadata": {},
   "source": [
    "### running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2c4b84-d4cf-4cc4-ba19-b1f866424e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret is false..\n",
      "release...!\n",
      "destroy windows...\n",
      "destroy windows...!\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    #print(i)\n",
    "    ret, frame = cp.read(0)\n",
    "\n",
    "    if ret==False:\n",
    "        print('ret is false..')\n",
    "        break;\n",
    "\n",
    "    gray_img = preprocessing(frame)\n",
    "    mnist_image = frame\n",
    "    \n",
    "    #------Requirement1: ROI-------#\n",
    "    contours, _ = cv2.findContours(gray_img.copy(), cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    rects = [cv2.boundingRect(contour) for contour in contours]\n",
    "    rects = [rect for rect in rects if rect[2] >= 3 and rect[3] >= 8]\n",
    "\n",
    "    \n",
    "    #-----Requirement2: ready for preprocessing frame------#\n",
    "    w2 = round(cp.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h2 = round(cp.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    prepro_image = np.ones((h2, w2), np.uint8) + 255\n",
    "    prepro_image.fill(255)   \n",
    "    prepro_image_to_bgr = cv2.cvtColor(prepro_image,cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    #------Requirement3: draw rectangles with prediction from classifer------#\n",
    "    for rect in rects:\n",
    "        x, y, w, h = rect\n",
    "        #print('x, y, w, h ', x, y, w, h )\n",
    "\n",
    "        if i >= 0:\n",
    "            mnist_frame = extract_digit(frame, rect, pad = 15)\n",
    "                        \n",
    "            if mnist_frame is not None: #and i % 25 == 0:\n",
    "                mnist_frame = np.expand_dims(mnist_frame, 0)\n",
    "                mnist_frame = np.expand_dims(mnist_frame, 3)\n",
    "                \n",
    "                result_arr = model.predict(mnist_frame)\n",
    "                class_prediction = np.argmax(result_arr, axis=1)\n",
    "\n",
    "                prediction = np.around(np.max(model.predict(mnist_frame, verbose = False)), 2)\n",
    "                label = str(prediction) # if you want probabilities\n",
    "\n",
    "                cv2.rectangle(mnist_image, (x, y), (x + w, y + h), color = (0, 255, 0), thickness=4)\n",
    "                label = str(class_prediction)\n",
    "                cv2.putText(mnist_image, label, (rect[0]+20, rect[1]-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            \n",
    "            #-----Requirement2: add cropped images on preprocessing frame----#\n",
    "\n",
    "                #create background square using longest length\n",
    "                max_wh = max(w,h)\n",
    "                square_bg = np.zeros((max_wh, max_wh), np.uint8)\n",
    "                square_bg2 = np.zeros((max_wh, max_wh, 3), np.uint8)\n",
    "\n",
    "                #calculate position\n",
    "                w_start = int((max_wh-w)/2)\n",
    "                h_start = int((max_wh-h)/2)\n",
    "                w_end = int((max_wh+w)/2)\n",
    "                h_end = int((max_wh+h)/2)\n",
    "\n",
    "                #get digit from gray, origin\n",
    "                cropped_gray_img = gray_img[y:y + h, x:x + w]\n",
    "                cropped_img = frame[y:y + h, x:x + w]\n",
    "\n",
    "                #add cropped image into background\n",
    "                square_bg[h_start:h_end, w_start:w_end] = cropped_gray_img.copy()\n",
    "                square_bg2[h_start:h_end, w_start:w_end] = cropped_img.copy()\n",
    "\n",
    "                #cv2.imshow('square_bg2',square_bg2)\n",
    "                #add squred preprocessing image into preprocessing_frame\n",
    "                try:\n",
    "                    prepro_image[y: y+max_wh, x: x+max_wh] = square_bg.copy()\n",
    "                    mnist_image[y+200: y+200+max_wh, x: x+max_wh] = square_bg2.copy()\n",
    "                    prepro_image_to_bgr = cv2.cvtColor(prepro_image,cv2.COLOR_GRAY2BGR)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    out.write(mnist_image)\n",
    "    out_pre.write(prepro_image_to_bgr)\n",
    "    #cv2.imshow('Result', mnist_image)\n",
    "    #cv2.imshow('preprocessing', prepro_image)\n",
    "    cv2.imshow(\"YoonjungChoi\", np.hstack([mnist_image, prepro_image_to_bgr]))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "        print('break')\n",
    "        break\n",
    "\n",
    "cp.release()\n",
    "out.release()\n",
    "out_pre.release()\n",
    "print('release...!')\n",
    "cv2.destroyAllWindows()\n",
    "print('destroy windows...')\n",
    "for i in range (1,5):\n",
    "    cv2.waitKey(1)\n",
    "print('destroy windows...!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7d3b0-143d-4838-9dd4-0a3b075dffe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1ec34-d7c7-481b-9392-032abef36573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
